{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name: Sai Anish Garapati\n",
    "# UIN: 650208577"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, time\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import shutil\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficImageDatset(Dataset):\n",
    "\tdef __init__(self, csv_file, root_dir, transform=None):\n",
    "\t\tself.csv_content = pd.read_csv(csv_file, usecols=['ClassId', 'Path'])\n",
    "\t\tself.root_dir = root_dir\n",
    "\t\tself.transform = transform\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.csv_content)\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\timg = Image.open(self.root_dir + self.csv_content.iloc[index, 1])\n",
    "\t\tlabel = torch.tensor(int(self.csv_content.iloc[index, 0]))\n",
    "\n",
    "\t\tif self.transform:\n",
    "\t\t\timg_tensor = self.transform(img)\n",
    "\n",
    "\t\treturn (img_tensor, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(2304, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 43)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(device, model, test_loader):\n",
    "    model.eval()\n",
    "    corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, label) in enumerate(test_loader):\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            output = model(data)\n",
    "            predictions = output.argmax(dim=1, keepdim=True)\n",
    "            corrects += predictions.eq(label.view_as(predictions)).sum().item()\n",
    "\n",
    "        print('Correct: {}, Total: {}, Test Accuracy: {}'.format(corrects, len(test_loader), 100.0 * corrects / len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 12121, Total: 12630, Test Accuracy: 95.96991290577989\n",
      "Test Time: 32.354490518569946\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2021)\n",
    "\n",
    "loaded_model = Net()\n",
    "loaded_model.load_state_dict(torch.load('./ML_Model.pt'))\n",
    "\n",
    "root_path = '../../../../ML_Project_Data/'\n",
    "test_batch_size=1\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.RandomCrop(32),\n",
    "    # transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "test_dataset = TrafficImageDatset(\n",
    "    csv_file=root_path + 'Test.csv', root_dir=root_path, transform=transform)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "start_time = time.time()\n",
    "test_model(device, loaded_model, test_loader)\n",
    "print('Test Time: {}'.format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sample(device, model, data):\n",
    "\tmodel.eval()\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tdata = data.to(device)\n",
    "\t\toutput = model(data.unsqueeze(0))\n",
    "\t\treturn output.argmax(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrects: 11979, Accuracy: 94.84560570071258\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2021)\n",
    "\n",
    "loaded_model = Net()\n",
    "loaded_model.load_state_dict(torch.load('./ML_Model.pt'))\n",
    "\n",
    "root_path = '../../../../ML_Project_Data/'\n",
    "transform = transforms.Compose([\n",
    "\ttransforms.Resize(32),\n",
    "\ttransforms.RandomCrop(32),\n",
    "\t# transforms.Grayscale(),\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_img_list = os.listdir(root_path + 'Test/')\n",
    "labels = pd.read_csv(root_path + 'Test.csv', usecols=['ClassId']).values\n",
    "\n",
    "correct = 0\n",
    "for test_img, label in zip(test_img_list, labels):\n",
    "\timg = Image.open(root_path + 'Test/' + test_img)\n",
    "\timg_tensor = transform(img)\n",
    "\tprediction = test_sample(device, loaded_model, img_tensor)\n",
    "\t# print(int(prediction), label[0])\n",
    "\tcorrect += (int(prediction) == label[0])\n",
    "\n",
    "print('Corrects: {}, Accuracy: {}'.format(correct, 100.0 * correct / len(test_img_list)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
