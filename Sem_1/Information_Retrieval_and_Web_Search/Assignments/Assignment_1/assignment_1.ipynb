{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Name: Sai Anish Garapati\r\n",
    "### UIN: 650208577"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import os, string\r\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.stem import PorterStemmer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions used for processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def preprocessing(path):\r\n",
    "\tfile_list = os.listdir(path)\r\n",
    "\r\n",
    "\tfile_string = ''\r\n",
    "\tfor file_name in file_list:\r\n",
    "\t\tfile = open(path + file_name, 'r')\r\n",
    "\t\tfile_string += file.read()\r\n",
    "\t\r\n",
    "\twords_list = word_tokenize(file_string)\r\n",
    "\twords_list = [word.translate(str.maketrans('', '', string.punctuation)) for word in words_list]\r\n",
    "\twords_list = [word.lower() for word in words_list if word != '']\r\n",
    "\treturn words_list\r\n",
    "\r\n",
    "def list_to_word_freq(words_list):\r\n",
    "\tword_freq = {}\r\n",
    "\tfor word in words_list:\r\n",
    "\t\tif word in word_freq:\r\n",
    "\t\t\tword_freq[word] += 1\r\n",
    "\t\telse:\r\n",
    "\t\t\tword_freq[word] = 1\r\n",
    "\treturn word_freq\r\n",
    "\r\n",
    "def remove_stop_words_from_dict(words_freq):\r\n",
    "\treturn {word: freq for (word, freq) in word_freq.items() if word not in stop_words}\r\n",
    "\r\n",
    "def stemmer_on_dict(words_freq):\r\n",
    "\tps = PorterStemmer()\r\n",
    "\twords_freq_stemmed = {}\r\n",
    "\r\n",
    "\tfor word, freq in words_freq.items():\r\n",
    "\t\tword = ps.stem(word)\r\n",
    "\t\tif (word in words_freq_stemmed):\r\n",
    "\t\t\twords_freq_stemmed[word] += freq\r\n",
    "\t\telse:\r\n",
    "\t\t\twords_freq_stemmed[word] = freq\r\n",
    "\treturn dict(sorted(words_freq_stemmed.items(), key=lambda item: item[1], reverse=True))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1) Preprocessing the collection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "path = 'citeseer/'\r\n",
    "words_list = preprocessing(path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2) Frequency of occurrence for all words "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "word_freq = list_to_word_freq(words_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.a) Total number of words in the collection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "print(len(words_list))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "477989\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.b) Vocabulary size"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "print(len(word_freq))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "19630\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.c) Top 20 words in the ranking"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "word_freq = dict(sorted(word_freq.items(), key=lambda item: item[1], reverse = True))\r\n",
    "word_freq_top_20 = dict(list(word_freq.items())[:20])\r\n",
    "print(word_freq_top_20)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'the': 25667, 'of': 18643, 'and': 14134, 'a': 13372, 'to': 11539, 'in': 10069, 'for': 7382, 'is': 6580, 'we': 5147, 'that': 4821, 'this': 4447, 'are': 3738, 'on': 3653, 'an': 3281, 'with': 3200, 'as': 3060, 'by': 2767, 'data': 2694, 'be': 2500, 'information': 2326}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.d) Stop words from top 20"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "stop_words = set(stopwords.words('english'))\r\n",
    "\r\n",
    "print([word for word in word_freq_top_20 if word in stop_words])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['the', 'of', 'and', 'a', 'to', 'in', 'for', 'is', 'we', 'that', 'this', 'are', 'on', 'an', 'with', 'as', 'by', 'be']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.e) Unique words accounting for 15% of total words"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "print(len([word for word in word_freq if word_freq[word] >= 0.15 * len(words_list)]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3) Integrating stemmer and stopword eliminator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Removing stop words from the vocabulary\r\n",
    "words_freq_new = remove_stop_words_from_dict(word_freq)\r\n",
    "\r\n",
    "# Applying stemmer on the new vocabulary\r\n",
    "words_freq_new_stemmed = stemmer_on_dict(words_freq_new)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.a) Total number of words in the new collection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "print(sum(words_freq_new_stemmed.values()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "294927\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.b) Vocabulary size"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "print(len(words_freq_new_stemmed))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "13625\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.c) Top 20 words in the ranking"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "print(dict(list(words_freq_new_stemmed.items())[:20]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'system': 3745, 'use': 3741, 'agent': 2695, 'data': 2694, 'inform': 2402, 'model': 2314, 'paper': 2247, 'queri': 1905, 'user': 1758, 'learn': 1742, 'algorithm': 1584, '1': 1569, 'problem': 1545, 'approach': 1544, 'applic': 1524, 'present': 1507, 'base': 1499, 'web': 1440, 'databas': 1425, 'comput': 1414}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.d) Stop words from top 20"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "print([word for word in dict(list(words_freq_new_stemmed.items())[:20]) if word in stop_words])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.e) Unique words accounting for 15% of total words"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "print(len([word for word in words_freq_new_stemmed if words_freq_new_stemmed[word]\r\n",
    "                           >= 0.15 * sum(words_freq_new_stemmed.values())]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}